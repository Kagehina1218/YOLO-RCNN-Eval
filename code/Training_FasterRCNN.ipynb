{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lCxVUHQtk9u4"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install cython\n",
        "!pip install 'git+https://github.com/facebookresearch/detectron2.git'\n",
        "!pip install opencv-python-headless\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u39o_JVdldvF"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Now set your DATA_ROOT to wherever you put your folders:\n",
        "DATA_ROOT = \"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W10JaRGmlds3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.engine import DefaultTrainer, DefaultPredictor\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader\n",
        "from detectron2.structures import BoxMode\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MqOmcUTldqP"
      },
      "outputs": [],
      "source": [
        "TRAIN_IMG_DIRS = [\n",
        "    os.path.join(DATA_ROOT, \"\"), #datapath to training images of fog\n",
        "    os.path.join(DATA_ROOT, \"\"), #datapath to training images of snow\n",
        "]\n",
        "TRAIN_LABEL_DIR = os.path.join(DATA_ROOT, \"\") #datapath to training labels\n",
        "\n",
        "VAL_IMG_DIRS = [\n",
        "    os.path.join(DATA_ROOT, \"\"), #datapath to validation images of fog\n",
        "    os.path.join(DATA_ROOT, \"\"), #datapath to validation images of snow\n",
        "]\n",
        "VAL_LABEL_DIR = os.path.join(DATA_ROOT, \"\") #datapath to validation labels\n",
        "\n",
        "TEST_IMG_DIR   = os.path.join(DATA_ROOT, \"\") #datapath to testing images\n",
        "TEST_LABEL_DIR = os.path.join(DATA_ROOT, \"\") #datapath to test labels\n",
        "\n",
        "CLASS_NAMES = [\n",
        "    'ambulance','army vehicle','auto rickshaw','bicycle','bus',\n",
        "    'car','garbagevan','human hauler','minibus','minivan',\n",
        "    'motorbike','pickup','policecar','rickshaw','scooter',\n",
        "    'suv','taxi','three wheelers -CNG-','truck','van','wheelbarrow'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7sJjd-7ldmm"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_yolo_dicts(img_dirs, label_dir):\n",
        "    dicts = []\n",
        "    for d in img_dirs:\n",
        "        for fn in os.listdir(d):\n",
        "            if not fn.lower().endswith((\".jpg\",\"png\")): continue\n",
        "            path = os.path.join(d, fn)\n",
        "            w, h = Image.open(path).size\n",
        "            rec = {\n",
        "                \"file_name\": path,\n",
        "                \"image_id\": f\"{os.path.basename(d)}_{os.path.splitext(fn)[0]}\",\n",
        "                \"height\": h, \"width\": w\n",
        "            }\n",
        "            annos = []\n",
        "            txt = os.path.join(label_dir, os.path.splitext(fn)[0] + \".txt\")\n",
        "            if os.path.exists(txt):\n",
        "                for line in open(txt):\n",
        "                    cid, cx, cy, rw, rh = map(float, line.split())\n",
        "                    x0 = (cx - rw/2) * w\n",
        "                    y0 = (cy - rh/2) * h\n",
        "                    annos.append({\n",
        "                        \"bbox\": [x0, y0, rw*w, rh*h],\n",
        "                        \"bbox_mode\": BoxMode.XYWH_ABS,\n",
        "                        \"category_id\": int(cid),\n",
        "                    })\n",
        "            rec[\"annotations\"] = annos\n",
        "            dicts.append(rec)\n",
        "    return dicts\n",
        "\n",
        "# Precompute & cache so DefaultTrainer starts instantly\n",
        "train_dicts = get_yolo_dicts(TRAIN_IMG_DIRS, TRAIN_LABEL_DIR)\n",
        "val_dicts   = get_yolo_dicts(VAL_IMG_DIRS,   VAL_LABEL_DIR)\n",
        "test_dicts  = get_yolo_dicts([TEST_IMG_DIR], TEST_LABEL_DIR)\n",
        "\n",
        "# Register splits\n",
        "DatasetCatalog.register(\"street_train\", lambda: train_dicts)\n",
        "MetadataCatalog.get(\"street_train\").set(thing_classes=CLASS_NAMES)\n",
        "DatasetCatalog.register(\"street_val\",   lambda: val_dicts)\n",
        "MetadataCatalog.get(\"street_val\").set(thing_classes=CLASS_NAMES)\n",
        "DatasetCatalog.register(\"street_test\",  lambda: test_dicts)\n",
        "MetadataCatalog.get(\"street_test\").set(thing_classes=CLASS_NAMES)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CrNafwNClbta"
      },
      "outputs": [],
      "source": [
        "# **Cell 4**: Configure & train on GPU (T4)\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(\n",
        "    model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_1x.yaml\")\n",
        ")\n",
        "# Use COCO pre-trained weights\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\n",
        "    \"COCO-Detection/faster_rcnn_R_50_FPN_1x.yaml\"\n",
        ")\n",
        "\n",
        "# Splits\n",
        "cfg.DATASETS.TRAIN = (\"street_train\",)\n",
        "cfg.DATASETS.TEST  = ()            # disable auto-validation during training\n",
        "\n",
        "# Speed tweaks (moderate resolution)\n",
        "cfg.INPUT.MIN_SIZE_TRAIN = (600,)  # default 800\n",
        "cfg.INPUT.MAX_SIZE_TRAIN = 1000    # default 1333\n",
        "cfg.INPUT.MIN_SIZE_TEST  = 600\n",
        "cfg.INPUT.MAX_SIZE_TEST  = 1000\n",
        "\n",
        "# DataLoader & Solver\n",
        "cfg.DATALOADER.NUM_WORKERS              = 4\n",
        "cfg.SOLVER.IMS_PER_BATCH                = 4\n",
        "cfg.SOLVER.BASE_LR                      = 1e-4\n",
        "cfg.SOLVER.MAX_ITER                     = 2000\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES         = len(CLASS_NAMES)\n",
        "\n",
        "# Output dir\n",
        "cfg.OUTPUT_DIR = \"./output_fast_gpu\"\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Train!\n",
        "trainer = DefaultTrainer(cfg)\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lmuk1SUPlbqR"
      },
      "outputs": [],
      "source": [
        "# **Cell 5**: Evaluate on validation set with COCO metrics\n",
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "cfg.DATASETS.TEST    = (\"street_test\",)  # now enable val split\n",
        "\n",
        "evaluator = COCOEvaluator(\"street_test\", cfg, False, output_dir=\"./output_test\")\n",
        "val_loader = build_detection_test_loader(cfg, \"street_test\")\n",
        "\n",
        "metrics = inference_on_dataset(trainer.model, val_loader, evaluator)\n",
        "print(\"=== COCO metrics on street_test ===\")\n",
        "print(metrics)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Make sure predictor is defined ===\n",
        "import os\n",
        "from detectron2.engine import DefaultPredictor\n",
        "\n",
        "# Point to your final model checkpoint\n",
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "# Only keep detections with score ≥ 0.5\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
        "\n",
        "predictor = DefaultPredictor(cfg)\n"
      ],
      "metadata": {
        "id": "La2Ln33SzwCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 6: Confusion Matrix + Example Prediction (with empty‐pred guard) ===\n",
        "\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import cv2\n",
        "\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog\n",
        "\n",
        "# 0) (Re)define predictor if needed\n",
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
        "predictor = DefaultPredictor(cfg)\n",
        "\n",
        "# 1) Build y_true / y_pred by matching each GT box to the best pred box (IoU ≥ 0.5)\n",
        "y_true, y_pred = [], []\n",
        "\n",
        "def xywh_to_xyxy(b):\n",
        "    x, y, w, h = b\n",
        "    return [x, y, x + w, y + h]\n",
        "\n",
        "for rec in val_dicts:\n",
        "    img = cv2.imread(rec[\"file_name\"])\n",
        "    outputs = predictor(img)[\"instances\"].to(\"cpu\")\n",
        "\n",
        "    # get predictions (may be empty)\n",
        "    if len(outputs.pred_boxes) == 0:\n",
        "        continue  # no predictions → skip this image entirely\n",
        "\n",
        "    pred_boxes   = outputs.pred_boxes.tensor.numpy()  # shape [N,4] in XYXY\n",
        "    pred_classes = outputs.pred_classes.numpy()       # shape [N]\n",
        "\n",
        "    for ann in rec[\"annotations\"]:\n",
        "        gt_box = np.array(xywh_to_xyxy(ann[\"bbox\"]))\n",
        "\n",
        "        # Compute IoU of this GT with every pred\n",
        "        ious = []\n",
        "        for pb in pred_boxes:\n",
        "            xi1 = max(gt_box[0], pb[0]); yi1 = max(gt_box[1], pb[1])\n",
        "            xi2 = min(gt_box[2], pb[2]); yi2 = min(gt_box[3], pb[3])\n",
        "            inter = max(0, xi2 - xi1) * max(0, yi2 - yi1)\n",
        "            area_gt = (gt_box[2] - gt_box[0]) * (gt_box[3] - gt_box[1])\n",
        "            area_pb = (pb[2] - pb[0]) * (pb[3] - pb[1])\n",
        "            union = area_gt + area_pb - inter\n",
        "            ious.append(inter / union if union > 0 else 0)\n",
        "\n",
        "        ious = np.array(ious)\n",
        "        best_i = ious.argmax()\n",
        "        if ious[best_i] >= 0.5:\n",
        "            y_true.append(ann[\"category_id\"])\n",
        "            y_pred.append(int(pred_classes[best_i]))\n",
        "        # else: we skip this GT (treat as unmatched)\n",
        "\n",
        "# 2) Compute & plot confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred, labels=list(range(len(CLASS_NAMES))))\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.imshow(cm, aspect='auto')\n",
        "plt.colorbar()\n",
        "plt.xticks(range(len(CLASS_NAMES)), CLASS_NAMES, rotation=90)\n",
        "plt.yticks(range(len(CLASS_NAMES)), CLASS_NAMES)\n",
        "plt.title(\"Confusion Matrix (IoU ≥ 0.5 matches)\")\n",
        "plt.xlabel(\"Predicted Class\")\n",
        "plt.ylabel(\"True Class\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 3) Show one random prediction example\n",
        "rec = random.choice(val_dicts)\n",
        "img = cv2.imread(rec[\"file_name\"])\n",
        "outputs = predictor(img)[\"instances\"].to(\"cpu\")\n",
        "\n",
        "v = Visualizer(\n",
        "    img[:, :, ::-1],\n",
        "    metadata=MetadataCatalog.get(\"street_val\"),\n",
        "    scale=1.0\n",
        ")\n",
        "out = v.draw_instance_predictions(outputs)\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.imshow(out.get_image()[:, :, ::-1])\n",
        "plt.axis(\"off\")\n",
        "plt.title(f\"Example: {os.path.basename(rec['file_name'])}\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "uKFxf-6zl6NS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) Compute & plot confusion matrix with white→blue colormap\n",
        "cm = confusion_matrix(y_true, y_pred, labels=list(range(len(CLASS_NAMES))))\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.imshow(cm, aspect='auto', cmap='Blues')      # add cmap='Blues'\n",
        "plt.colorbar()\n",
        "plt.xticks(range(len(CLASS_NAMES)), CLASS_NAMES, rotation=90)\n",
        "plt.yticks(range(len(CLASS_NAMES)), CLASS_NAMES)\n",
        "plt.title(\"Confusion Matrix (IoU ≥ 0.5 matches)\")\n",
        "plt.xlabel(\"Predicted Class\")\n",
        "plt.ylabel(\"True Class\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "nSQEwr6tmMMM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}